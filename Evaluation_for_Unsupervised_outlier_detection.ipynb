{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Evaluation for Unsupervised outlier detection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO8iidrHbJaGAQxNRcRofIz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mulaab/Outlier-Detection/blob/main/Evaluation_for_Unsupervised_outlier_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUTGwbAWMttf"
      },
      "source": [
        "## In this topic, we present about the measures for anomaly detection if we use method unsupervised outlier detection. We know that unsupervised outlier detection using  data without label. We will show one methods for it which em mv mehods. the first step we install pyod and  and emmv library with command pip install pyod and pip install emmv\n",
        "\n",
        "> ! pip install pyod \n",
        "\n",
        ">  ! pip install emmv block\n",
        "\n",
        ">  !pip list -v for know list of packages in colab\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_leuOIXFCZ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34626d44-90f1-4541-ba82-f3a2411382e8"
      },
      "source": [
        "!pip install emmv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting emmv\n",
            "  Downloading emmv-0.0.4-py3-none-any.whl (4.0 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from emmv) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from emmv) (0.22.2.post1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from emmv) (57.4.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from emmv) (1.1.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->emmv) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->emmv) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->emmv) (1.15.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->emmv) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->emmv) (1.0.1)\n",
            "Installing collected packages: emmv\n",
            "Successfully installed emmv-0.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAkd65I-JoAR"
      },
      "source": [
        "!pip install pyod"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EjP_BQdAoUEf",
        "outputId": "df34072b-3f80-40ca-8000-87d14da9bc55"
      },
      "source": [
        "!pip install adtk"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting adtk\n",
            "  Downloading adtk-0.6.2-py3-none-any.whl (60 kB)\n",
            "\u001b[?25l\r\u001b[K     |█████▍                          | 10 kB 25.0 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 20 kB 27.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 30 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 40 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 51 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 60 kB 3.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.7/dist-packages (from adtk) (21.0)\n",
            "Requirement already satisfied: pandas>=0.23 in /usr/local/lib/python3.7/dist-packages (from adtk) (1.1.5)\n",
            "Requirement already satisfied: matplotlib>=3.0 in /usr/local/lib/python3.7/dist-packages (from adtk) (3.2.2)\n",
            "Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.7/dist-packages (from adtk) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from adtk) (1.19.5)\n",
            "Requirement already satisfied: statsmodels>=0.9 in /usr/local/lib/python3.7/dist-packages (from adtk) (0.10.2)\n",
            "Requirement already satisfied: tabulate>=0.8 in /usr/local/lib/python3.7/dist-packages (from adtk) (0.8.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0->adtk) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0->adtk) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0->adtk) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0->adtk) (2.8.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib>=3.0->adtk) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23->adtk) (2018.9)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20->adtk) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20->adtk) (1.0.1)\n",
            "Requirement already satisfied: patsy>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from statsmodels>=0.9->adtk) (0.5.2)\n",
            "Installing collected packages: adtk\n",
            "Successfully installed adtk-0.6.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fO9L0UW-7EE",
        "outputId": "d7a537cf-2877-4625-a60a-c80223dc7725"
      },
      "source": [
        "!pip install combo"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting combo\n",
            "  Downloading combo-0.1.2.tar.gz (37 kB)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from combo) (1.0.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from combo) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.13 in /usr/local/lib/python3.7/dist-packages (from combo) (1.19.5)\n",
            "Requirement already satisfied: numba>=0.35 in /usr/local/lib/python3.7/dist-packages (from combo) (0.51.2)\n",
            "Requirement already satisfied: pyod in /usr/local/lib/python3.7/dist-packages (from combo) (0.9.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from combo) (1.5.4)\n",
            "Requirement already satisfied: scikit_learn>=0.20 in /usr/local/lib/python3.7/dist-packages (from combo) (0.23.2)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.35->combo) (0.34.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.35->combo) (57.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit_learn>=0.20->combo) (3.0.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->combo) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->combo) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->combo) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->combo) (2.8.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib->combo) (1.15.0)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.7/dist-packages (from pyod->combo) (0.10.2)\n",
            "Requirement already satisfied: pandas>=0.19 in /usr/local/lib/python3.7/dist-packages (from statsmodels->pyod->combo) (1.1.5)\n",
            "Requirement already satisfied: patsy>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from statsmodels->pyod->combo) (0.5.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.19->statsmodels->pyod->combo) (2018.9)\n",
            "Building wheels for collected packages: combo\n",
            "  Building wheel for combo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for combo: filename=combo-0.1.2-py3-none-any.whl size=42025 sha256=1b8c9f4924310e53d4477b7748025f74652ed4dc593f20de76dd64d69edcea10\n",
            "  Stored in directory: /root/.cache/pip/wheels/cf/2e/45/d4cb985fb061e3ab636d350b76114d2639d84eab16225c7776\n",
            "Successfully built combo\n",
            "Installing collected packages: combo\n",
            "Successfully installed combo-0.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGAJWVY9-kyk",
        "outputId": "3b999897-4f7d-4e7c-e4df-ead5b5398eee"
      },
      "source": [
        "import numpy as np\n",
        "from pyod.models.copod import COPOD\n",
        "\n",
        "from emmv import emmv_scores\n",
        "\n",
        "rng = np.random.RandomState(42)\n",
        "\n",
        "NUM_COLS = 7\n",
        "# Generate train data\n",
        "X = 0.3 * rng.randn(100, NUM_COLS)\n",
        "X_train = np.r_[X + 2, X - 2]\n",
        "# Generate some regular novel observations\n",
        "X = 0.3 * rng.randn(20, NUM_COLS)\n",
        "X_regular = np.r_[X + 2, X - 2]\n",
        "# Generate some abnormal novel observations\n",
        "X_outliers = rng.uniform(low=-4, high=4, size=(20, NUM_COLS))\n",
        "# fit the model\n",
        "model = COPOD()\n",
        "model.fit(X_train)\n",
        "\n",
        "# Get EM & MV scores\n",
        "X_test = np.concatenate((X_regular, X_outliers), axis=0)\n",
        "test_scores = emmv_scores(model, X_test)\n",
        "print('Excess Mass score;', test_scores['em'])\n",
        "print('Mass Volume score:', test_scores['mv'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Excess Mass score; 0.0072596801\n",
            "Mass Volume score: 1067810.6455843074\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9PM2ec3oP7d",
        "outputId": "fb94b781-067f-452d-f832-d18a7e3a9f56"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from adtk.data import validate_series\n",
        "from adtk.detector import GeneralizedESDTestAD\n",
        "\n",
        "from emmv import emmv_scores\n",
        "\n",
        "rng = np.random.RandomState(42)\n",
        "\n",
        "# Generate train data\n",
        "timestamps = pd.date_range(\"2018-01-01\", periods=200, freq=\"H\")\n",
        "X = 0.3 * rng.randn(100)\n",
        "values = np.r_[X + 2, X - 2]\n",
        "data = pd.Series(values, index=timestamps)\n",
        "X_train = validate_series(data)\n",
        "\n",
        "# Generate some regular novel observations\n",
        "X = 0.3 * rng.randn(67)\n",
        "X_regular = np.r_[X + 2, X - 2]\n",
        "# Generate some abnormal novel observations\n",
        "X_outliers = rng.uniform(low=-4, high=4, size=(66))\n",
        "# Create test data\n",
        "timestamps = pd.date_range(\"2018-01-01\", periods=200, freq=\"H\")\n",
        "values = np.concatenate((X_regular, X_outliers), axis=0)\n",
        "data = pd.Series(values, index=timestamps)\n",
        "X_test = validate_series(data)\n",
        "\n",
        "# Fit model\n",
        "model = GeneralizedESDTestAD()\n",
        "anomalies = model.fit_detect(X_train)\n",
        "\n",
        "# Get EM & MV scores\n",
        "\n",
        "# TF models do not have a \"decision_function\" method, so we need to specify\n",
        "# our own custom anomaly scoring function. This one is specific to GeneralizedESDTestAD.\n",
        "# It is adapted from: https://github.com/odnura/adtk/blob/73bfb30ba457dd540e8aea82782431254da480ce/src/adtk/detector/_detector_1d.py#L346\n",
        "def scoring_function(model, df):\n",
        "    s = pd.Series(df) # 1D data expected\n",
        "    new_sum = s + model._normal_sum\n",
        "    new_count = model._normal_count + 1\n",
        "    new_mean = new_sum / new_count\n",
        "    new_squared_sum = s ** 2 + model._normal_squared_sum\n",
        "    new_std = np.sqrt(\n",
        "        (\n",
        "            new_squared_sum\n",
        "            - 2 * new_mean * new_sum\n",
        "            + new_count * new_mean ** 2\n",
        "        )\n",
        "        / (new_count - 1)\n",
        "    )\n",
        "    anomaly_scores = (s - new_mean).abs() / new_std\n",
        "    return anomaly_scores\n",
        "\n",
        "test_scores = emmv_scores(model, X_test, scoring_function)\n",
        "print('Excess Mass score;', test_scores['em'])\n",
        "print('Mass Volume score:', test_scores['mv'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Excess Mass score; 0.006291853399999999\n",
            "Mass Volume score: 6.5658257289213795\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tgzM40SIo3wi",
        "outputId": "30e154ad-33b9-4913-dc1b-a262e4db75e3"
      },
      "source": [
        "'''\n",
        "Author: Christian O'Leary\n",
        "Email: cjjoleary@gmail.com\n",
        "'''\n",
        "\n",
        "import os\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, InputLayer\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "from emmv import emmv_scores\n",
        "\n",
        "seed = 42\n",
        "os.environ['PYTHONHASHSEED']=str(seed)\n",
        "random.seed(seed)\n",
        "rng = np.random.RandomState(seed)\n",
        "tf.random.set_seed(seed)\n",
        "NUM_COLS = 1\n",
        "\n",
        "# Generate train data\n",
        "X = 0.3 * rng.randn(100, NUM_COLS)\n",
        "X_train = np.r_[X + 2, X - 2]\n",
        "# Generate some regular novel observations\n",
        "X = 0.3 * rng.randn(20, NUM_COLS)\n",
        "X_regular = np.r_[X + 2, X - 2]\n",
        "# Generate some abnormal novel observations\n",
        "X_outliers = rng.uniform(low=-4, high=4, size=(20, NUM_COLS))\n",
        "X_test = np.concatenate((X_regular, X_outliers), axis=0)\n",
        "\n",
        "# fit the model\n",
        "model = Sequential([\n",
        "            InputLayer(input_shape=NUM_COLS),\n",
        "            Dense(32),\n",
        "            Dense(NUM_COLS, activation='relu')\n",
        "        ])\n",
        "model.compile(loss='mse', optimizer='adam')\n",
        "model.fit(\n",
        "    X_train,\n",
        "    X_train, # i.e. reconstruction model\n",
        "    validation_split=0.1,\n",
        "    epochs=20,\n",
        "    batch_size=64,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Get EM & MV scores\n",
        "\n",
        "# TF models do not have a \"decision_function\" method, so we need to specify\n",
        "# our own custom anomaly scoring function. This one uses MAPE.\n",
        "def scoring_function(model, df):\n",
        "    offset = 0.00000001 # to prevent division by 0\n",
        "    # 1. model predictions\n",
        "    preds = model.predict(df)\n",
        "    # 2. Use a regression metric, e.g. MAPE\n",
        "    anomaly_scores = np.mean((np.abs(preds - df) / (df + offset)), axis=1) # i.e. anomaly score\n",
        "    return anomaly_scores\n",
        "\n",
        "test_scores = emmv_scores(model, X_test, scoring_function)\n",
        "print('Excess Mass score;', test_scores['em'])\n",
        "print('Mass Volume score:', test_scores['mv'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "3/3 [==============================] - 0s 64ms/step - loss: 3.1599 - val_loss: 4.0695\n",
            "Epoch 2/20\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 2.9964 - val_loss: 4.0695\n",
            "Epoch 3/20\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 2.8433 - val_loss: 4.0695\n",
            "Epoch 4/20\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 2.7012 - val_loss: 4.0695\n",
            "Epoch 5/20\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.5698 - val_loss: 4.0695\n",
            "Epoch 6/20\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 2.4601 - val_loss: 4.0695\n",
            "Epoch 7/20\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 2.3511 - val_loss: 4.0695\n",
            "Epoch 8/20\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 2.2648 - val_loss: 4.0695\n",
            "Epoch 9/20\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 2.1843 - val_loss: 4.0695\n",
            "Epoch 10/20\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.1174 - val_loss: 4.0695\n",
            "Epoch 11/20\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 2.0622 - val_loss: 4.0695\n",
            "Epoch 12/20\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 2.0156 - val_loss: 4.0695\n",
            "Epoch 13/20\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 1.9776 - val_loss: 4.0695\n",
            "Epoch 14/20\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 1.9509 - val_loss: 4.0695\n",
            "Epoch 15/20\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 1.9269 - val_loss: 4.0695\n",
            "Epoch 16/20\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 1.9110 - val_loss: 4.0695\n",
            "Epoch 17/20\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 1.8998 - val_loss: 4.0695\n",
            "Epoch 18/20\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 1.8919 - val_loss: 4.0695\n",
            "Epoch 19/20\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 1.8870 - val_loss: 4.0695\n",
            "Epoch 20/20\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 1.8843 - val_loss: 4.0695\n",
            "Excess Mass score; 0.005821040033333333\n",
            "Mass Volume score: 5.275107931454706\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9k8Xhz9wpKou"
      },
      "source": [
        "'''\n",
        "Author: Christian O'Leary\n",
        "Email: cjjoleary@gmail.com\n",
        "'''\n",
        "\n",
        "from emmv import emmv_scores\n",
        "\n",
        "# Adapted from https://pycaret.org/setup/\n",
        "# Importing dataset\n",
        "from pycaret.datasets import get_data\n",
        "anomalies = get_data('anomaly')\n",
        "\n",
        "# Importing module and initializing setup\n",
        "from pycaret.anomaly import *\n",
        "anomaly_setup = setup(data=anomalies)\n",
        "\n",
        "# create a model\n",
        "model = create_model('iforest')\n",
        "results = assign_model(model)\n",
        "\n",
        "# Get EM & MV scores\n",
        "test_scores = emmv_scores(model, anomalies)\n",
        "print('Excess Mass score;', test_scores['em'])\n",
        "print('Mass Volume score:', test_scores['mv'])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}